{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600f5f49",
   "metadata": {},
   "source": [
    "# Movie Model Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a3ce1",
   "metadata": {},
   "source": [
    "The script presented below illustrates the data preprocessing and training processes we employed to develop our machine learning model. Approaching this project, our primary challenge was acquiring hands-on experience in machine learning, a field in which we initially had minimal expertise. We recognize that the implementation may be rudimentary adn kind of naive, particularly regarding the predictive methodology, which might not represent the most effective strategy. Nevertheless, we take pride in having operational models, despite acknowledging the potential for further enhancement in their predictive accuracy. It is also important to note that we extensively used ChatGPT to assist with the model training procedures, given our limited prior knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e4da5",
   "metadata": {},
   "source": [
    "Note: in the script below we only used a small part of our dataset (10000 movies) for the training, since it would have taken too much time and storage to train and save it to our local machines. Therefore, the following script serves as a demonstration which can be performed and tested on your local device.\n",
    "We trained the model on the whole dataset on a different machine, but the same code (just adjusted for whole dataset). We uploaded this model to Hugging Face and then fetched it later on in our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afecdfe0",
   "metadata": {},
   "source": [
    "### Data loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97dc0b",
   "metadata": {},
   "source": [
    "In the two following code blocks we load and preprocess our data. The overall goal is to facilitate the training of a model that can predict similar movies based on genre, which could be used in the recommendation system. The structuring of movie pairs based on genre similarity provides a focused dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e53ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class MoviePairDataset(Dataset):\n",
    "    def __init__(self, preferred_movie_ids, similar_movie_ids):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            preferred_movie_ids (list of int): The IDs of the preferred movies.\n",
    "            similar_movie_ids (list of int): The IDs of movies similar to the preferred ones.\n",
    "        \"\"\"\n",
    "        assert len(preferred_movie_ids) == len(similar_movie_ids), \"The lists must have the same length.\"\n",
    "        self.preferred_movie_ids = preferred_movie_ids\n",
    "        self.similar_movie_ids = similar_movie_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.preferred_movie_ids)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        preferred_id = torch.tensor(self.preferred_movie_ids[idx], dtype=torch.long)\n",
    "        similar_id = torch.tensor(self.similar_movie_ids[idx], dtype=torch.long)\n",
    "        return preferred_id, similar_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e725d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict by genre created\n"
     ]
    }
   ],
   "source": [
    "# size of the dataset\n",
    "num_movie_ids = 10000 \n",
    "\n",
    "# path to the dataset folder\n",
    "data_folder = \"../data/\"\n",
    "\n",
    "# list all CSV files in the data directory\n",
    "csv_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "\n",
    "# load all CSV files into a single DataFrame\n",
    "all_movies_df = pd.concat(\n",
    "    (pd.read_csv(f\"{data_folder}{file}\") for file in csv_files),\n",
    "    ignore_index=True\n",
    ")[:num_movie_ids]\n",
    "\n",
    "# define the thresholds for the similarity of movies\n",
    "RATING_DIFF_THRESHOLD = 1.0  # movies within this rating difference are considered similar\n",
    "YEAR_DIFF_THRESHOLD = 5  # movies within this range of years are considered similar\n",
    "\n",
    "# initialize lists to store the IDs of the preferred and similar movies\n",
    "preferred_movie_ids = []\n",
    "similar_movie_ids = []\n",
    "\n",
    "# lists of movies by genre\n",
    "genres = {}\n",
    "lst = all_movies_df.values.tolist()\n",
    "for i, l in enumerate(lst):\n",
    "    genre = []\n",
    "    if l[5] in genres:\n",
    "        genre = genres[l[5]]\n",
    "    else:\n",
    "        genres[l[5]] = genre\n",
    "    genre.append([i, l[1]])\n",
    "print('Dict by genre created')\n",
    "\n",
    "# create dataset from pairs: movie + random movie with same genre\n",
    "import random    \n",
    "for row_idx, row in all_movies_df.iterrows():\n",
    "    same_genre_movies = genres[row['genre']] # get all movies of the same genre\n",
    "    pos = row_idx\n",
    "    while pos == row_idx:\n",
    "        pos = random.randint(0, len(same_genre_movies) - 1) # get a random movie of the same genre\n",
    "    similar_movie_ids.append(same_genre_movies[pos][0]) # add the random movie to the list of similar movies\n",
    "    preferred_movie_ids.append(row_idx) # add the preferred movie to the list of preferred movies\n",
    "\n",
    "# create dataset from pairs: movie + random movie with same genre\n",
    "dataset = MoviePairDataset(preferred_movie_ids=preferred_movie_ids, similar_movie_ids=similar_movie_ids)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "# create dataset from pairs: movie + random movie with same genre (same as above, should be like 90%/10% split, but would perform worse - so just for demo)\n",
    "eval_dataset = MoviePairDataset(preferred_movie_ids=preferred_movie_ids, similar_movie_ids=similar_movie_ids)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595582cc",
   "metadata": {},
   "source": [
    "### Neural Network Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa73b84",
   "metadata": {},
   "source": [
    "The following code defines a neural network model named MovieIDPredictor using PyTorch, designed for predicting movie IDs. The model follows the Transformer architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b4eb945-b914-4f55-b42e-6da9c4e76a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MovieIDPredictor(nn.Module):\n",
    "    def __init__(self, num_movie_ids, movie_id_embedding_dim=64, transformer_heads=8, transformer_layers=1, transformer_dim=64):\n",
    "        super(MovieIDPredictor, self).__init__()\n",
    "        self.movie_id_embedding_dim = movie_id_embedding_dim # Dimension of the movie ID embeddings\n",
    "        self.transformer_dim = transformer_dim # Dimension of the transformer output\n",
    "\n",
    "        # ensure the embedding dimension for movie_id matches the transformer dimension\n",
    "        self.movie_id_embedding = nn.Embedding(num_movie_ids, self.movie_id_embedding_dim)\n",
    "\n",
    "        # eransformer layer\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=self.transformer_dim, nhead=transformer_heads), num_layers=transformer_layers)\n",
    "        \n",
    "        # output layer to classify movie IDs (stays unchanged)\n",
    "        self.fc_out = nn.Linear(self.transformer_dim, num_movie_ids)\n",
    "        \n",
    "    def forward(self, movie_id):\n",
    "        movie_id_emb = self.movie_id_embedding(movie_id).view(-1, 1, self.movie_id_embedding_dim) # embedding layer\n",
    "        x = self.transformer(movie_id_emb) # transformer\n",
    "        x = x.view(-1, self.transformer_dim) # flatten the output\n",
    "        output = self.fc_out(x) # output layer\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589cc1d6",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79663d59",
   "metadata": {},
   "source": [
    "The following code is for the setup and execution of a training loop for the neural network model designed to predict similar movie IDs from preferred movie IDs. The training loop leverages supervised learning as it uses a dataset that contains both the inputs and the corresponding target outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "913be044-e97e-45e8-abd8-d859cfa9b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmakozmer/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 9.4150, Validation Loss: 8.9467\n",
      "Validation loss decreased (inf --> 8.9467). Saving model ...\n",
      "Epoch 2, Training Loss: 8.6678, Validation Loss: 8.0072\n",
      "Validation loss decreased (8.9467 --> 8.0072). Saving model ...\n",
      "Epoch 3, Training Loss: 7.9888, Validation Loss: 7.0574\n",
      "Validation loss decreased (8.0072 --> 7.0574). Saving model ...\n",
      "Epoch 4, Training Loss: 7.0418, Validation Loss: 5.7033\n",
      "Validation loss decreased (7.0574 --> 5.7033). Saving model ...\n",
      "Epoch 5, Training Loss: 5.7061, Validation Loss: 3.9427\n",
      "Validation loss decreased (5.7033 --> 3.9427). Saving model ...\n",
      "Epoch 6, Training Loss: 4.0778, Validation Loss: 2.0817\n",
      "Validation loss decreased (3.9427 --> 2.0817). Saving model ...\n",
      "Epoch 7, Training Loss: 2.4160, Validation Loss: 0.7742\n",
      "Validation loss decreased (2.0817 --> 0.7742). Saving model ...\n",
      "Epoch 8, Training Loss: 1.0816, Validation Loss: 0.2092\n",
      "Validation loss decreased (0.7742 --> 0.2092). Saving model ...\n",
      "Epoch 9, Training Loss: 0.3822, Validation Loss: 0.0578\n",
      "Validation loss decreased (0.2092 --> 0.0578). Saving model ...\n",
      "Epoch 10, Training Loss: 0.1451, Validation Loss: 0.0225\n",
      "Validation loss decreased (0.0578 --> 0.0225). Saving model ...\n",
      "Epoch 11, Training Loss: 0.0679, Validation Loss: 0.0104\n",
      "Validation loss decreased (0.0225 --> 0.0104). Saving model ...\n",
      "Epoch 12, Training Loss: 0.0467, Validation Loss: 0.0088\n",
      "Validation loss decreased (0.0104 --> 0.0088). Saving model ...\n",
      "Epoch 13, Training Loss: 0.0349, Validation Loss: 0.0059\n",
      "Validation loss decreased (0.0088 --> 0.0059). Saving model ...\n",
      "Epoch 14, Training Loss: 0.0203, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.0059 --> 0.0030). Saving model ...\n",
      "Epoch 15, Training Loss: 0.0218, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.0030 --> 0.0027). Saving model ...\n",
      "Epoch 16, Training Loss: 0.0182, Validation Loss: 0.0017\n",
      "Validation loss decreased (0.0027 --> 0.0017). Saving model ...\n",
      "Epoch 17, Training Loss: 0.0092, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.0017 --> 0.0011). Saving model ...\n",
      "Epoch 18, Training Loss: 0.0046, Validation Loss: 0.0004\n",
      "Validation loss decreased (0.0011 --> 0.0004). Saving model ...\n",
      "Epoch 19, Training Loss: 0.0088, Validation Loss: 0.0009\n",
      "Epoch 20, Training Loss: 0.0060, Validation Loss: 0.0005\n",
      "Epoch 21, Training Loss: 0.0036, Validation Loss: 0.0003\n",
      "Validation loss decreased (0.0004 --> 0.0003). Saving model ...\n",
      "Epoch 22, Training Loss: 0.0019, Validation Loss: 0.0004\n",
      "Epoch 23, Training Loss: 0.0043, Validation Loss: 0.0002\n",
      "Validation loss decreased (0.0003 --> 0.0002). Saving model ...\n",
      "Epoch 24, Training Loss: 0.0024, Validation Loss: 0.0006\n",
      "Epoch 25, Training Loss: 0.0092, Validation Loss: 0.0009\n",
      "Epoch 26, Training Loss: 0.0058, Validation Loss: 0.0002\n",
      "Validation loss decreased (0.0002 --> 0.0002). Saving model ...\n",
      "Epoch 27, Training Loss: 0.0016, Validation Loss: 0.0001\n",
      "Validation loss decreased (0.0002 --> 0.0001). Saving model ...\n",
      "Epoch 28, Training Loss: 0.0007, Validation Loss: 0.0000\n",
      "Validation loss decreased (0.0001 --> 0.0000). Saving model ...\n",
      "Epoch 29, Training Loss: 0.0004, Validation Loss: 0.0000\n",
      "Validation loss decreased (0.0000 --> 0.0000). Saving model ...\n",
      "Epoch 30, Training Loss: 0.0004, Validation Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# set the device to be used for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model initialization\n",
    "model = MovieIDPredictor(num_movie_ids=num_movie_ids, movie_id_embedding_dim=64, transformer_heads=8, transformer_layers=1, transformer_dim=64)\n",
    "\n",
    "model.to(device) # move the model to the device\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# training loop setup\n",
    "num_epochs = 30\n",
    "\n",
    "lowest_val_loss = float('inf') # to track the lowest validation loss\n",
    "best_model_state = None  # to save the best model state\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  #set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    # Training step\n",
    "    for preferred_id, similar_id in dataloader:\n",
    "        preferred_id, similar_id = preferred_id.to(device), similar_id.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(preferred_id)\n",
    "        loss = criterion(outputs, similar_id)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(dataloader) # average training loss\n",
    "\n",
    "    # evaluation step\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for preferred_id, similar_id in dataloader:\n",
    "            preferred_id, similar_id = preferred_id.to(device), similar_id.to(device)\n",
    "            outputs = model(preferred_id)\n",
    "            loss = criterion(outputs, similar_id)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(eval_dataloader) # average validation loss\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # check if the current validation loss is the lowest\n",
    "    if avg_val_loss < lowest_val_loss:\n",
    "        print(f'Validation loss decreased ({lowest_val_loss:.4f} --> {avg_val_loss:.4f}). Saving model ...')\n",
    "        lowest_val_loss = avg_val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "best_model_state_cpu = {k: v.cpu() for k, v in best_model_state.items()} # move the best model state to the CPU\n",
    "torch.save(best_model_state_cpu, 'movie_predictor_model.pth') # save the best model state to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1861b810",
   "metadata": {},
   "source": [
    "### Load Model Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07424911",
   "metadata": {},
   "source": [
    "Load the model weights for the validation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9e2ca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieIDPredictor(\n",
       "  (movie_id_embedding): Embedding(10000, 64)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=64, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "loaded_model = MovieIDPredictor(num_movie_ids=num_movie_ids)\n",
    "\n",
    "# load the state dictionary\n",
    "loaded_model.load_state_dict(torch.load('../models/movie_predictor_model.pth')) \n",
    "\n",
    "# set the model to evaluation mode\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3e089",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b907e09d-02a1-420a-ace0-4d5cff60eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the evaluation dataset: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # no need to track gradients during evaluation\n",
    "    for preferred_id, similar_id in dataloader:  # assuming you have a dataloader for your evaluation dataset\n",
    "        outputs = loaded_model(preferred_id)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # get the index of the max log-probability\n",
    "        total += similar_id.size(0)\n",
    "        correct += (predicted == similar_id).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the evaluation dataset: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab46e1",
   "metadata": {},
   "source": [
    "### Example of a Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a7d8a",
   "metadata": {},
   "source": [
    "The following code illustrates an example of a movie recommendation with the model which was trained in the scripts before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "697f0985-133f-4ec7-9a97-3699a1ec07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Movie IDs for Movie ID 20: [5350, 7299, 7324, 8470, 3605]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def predict(movie_id, n):\n",
    "    \"\"\"\n",
    "    Predicts the top n recommended movie_ids for a given movie_id.\n",
    "\n",
    "    Args:\n",
    "    movie_id (int): The movie ID for which recommendations are to be made.\n",
    "    n (int): The number of recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of the top n recommended movie IDs.\n",
    "    \"\"\"\n",
    "    # convert movie_id to a tensor and add a batch dimension (batch size = 1)\n",
    "    movie_id_tensor = torch.tensor([movie_id], dtype=torch.long)\n",
    "    \n",
    "    # ensure the model is in evaluation mode\n",
    "    loaded_model.eval()\n",
    "    \n",
    "    with torch.no_grad():  # Inference doesn't require gradient calculation\n",
    "        # get model output for the given movie_id\n",
    "        outputs = loaded_model(movie_id_tensor)\n",
    "        \n",
    "        # get the scores, ignore the first recommendation as it's the movie itself\n",
    "        _, recommended_ids = torch.topk(outputs, n + 1, dim=1)\n",
    "        \n",
    "        # convert to a list and remove the input movie_id from the recommendations\n",
    "        recommended_ids = recommended_ids[0].tolist()\n",
    "        if movie_id in recommended_ids:\n",
    "            recommended_ids.remove(movie_id)\n",
    "        else:  # if the movie_id is not in the top n+1, remove the last to keep n recommendations\n",
    "            recommended_ids.pop()\n",
    "\n",
    "    return recommended_ids[:n]\n",
    "\n",
    "movie_id = 20  # example movie ID\n",
    "n = 5  # number of recommendations\n",
    "recommended_movie_ids = predict(movie_id, n) # get recommendations\n",
    "print(f\"Recommended Movie IDs for Movie ID {movie_id}: {recommended_movie_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3021d0bc",
   "metadata": {},
   "source": [
    "## Upload Model to Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb3ebc",
   "metadata": {},
   "source": [
    "For the training of the whole model we then used the following code to upload it to Hugging Face (as it would be too large to push in to GitHub). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f67c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd87017",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_repo(\"movie_match_model\", private=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
